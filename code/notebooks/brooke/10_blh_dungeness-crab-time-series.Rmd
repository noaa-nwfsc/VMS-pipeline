---
title: "10_blh_dungeness-crab-time-series"
author: "Brooke Hawkins"
date: "`r Sys.Date()`"
output: html_document
---

```{r, include=FALSE}
# start timer
start_timer <- proc.time()
```

## Focus: Time series

* Landings and revenue time series from fish tickets for main deck

```{r setup, include=FALSE}
# import libraries
library(tidyverse)
library(here)
library(fredr)
```

```{r create-output-directories}
# make hidncast output directory, if doesn't yet exist
output_dir <- here('Confidential', 'hindcast_output')
if (!dir.exists(output_dir)) dir.create(output_dir)

# create hindcast output subdirectory name based on system date
output_subdir_name <- paste0("hindcast_output_", Sys.Date())

# make hindcast output subdirectory, if doesn't yet exist
output_subdir <- here('Confidential', 'hindcast_output', output_subdir_name)
if (!dir.exists(output_subdir)) dir.create(output_subdir)

# make tables, figures, and maps subdirectories
for (temp_name in c('tables', 'figures', 'maps')) {
  temp_subdir <- here('Confidential', 'hindcast_output', output_subdir_name, temp_name)
  if (!dir.exists(temp_subdir)) dir.create(temp_subdir)
}
rm(temp_name, temp_subdir)
```

## Load data

1. Load the cleaned fish ticket data for specified years, which will be used to plot revenue and landings across time.

Pre-requisite: Run the pipeline steps 1-6 (including interpolation) for calendar years 2011-2023 for DCRB.

```{r load-data}
# choose years of data to load
load_years <- 2011:2023

# load fish ticket data before it was joined to VMS data, used to check VMS representativeness
ticket_df <- purrr::map(load_years, function(ly) {
  read_rds(here('Confidential', 'processed_data', 'processed_2025-03-19', 'fish_tickets', paste0('fishtix_vlengths_withFTID_', ly, '.rds')))
}) %>% bind_rows()
```

2. Load inflation adjustment factors from FRED.

Adjust revenue for inflation using Fred GDP data, adapted from R code by Erin Steiner. This product uses the FREDÂ® API but is not endorsed or certified by the Federal Reserve Bank of St. Louis.

Pre-requisite: Create a FRED account and API key. See https://fred.stlouisfed.org/docs/api/api_key.html.

```{r inflation-adjustment}
# insert your FRED API key
fredr_set_key('')

# download the quarterly inflation adjustments from Fred from 1985 to present
fred_gdpdefl <- fredr(
    series_id = "GDPDEF", 
    observation_start = as.Date(paste0(min(load_years), "-01-01"))
  )

# generate the mean annual deflators based on the quarterly values
gdp_defl <- mutate(fred_gdpdefl, year = year(date)) %>%
  group_by(year) %>%
  summarize(defl = mean(value), .groups = 'drop') %>%
  mutate(inflation_adjustment_factor = defl / defl[year == max(year)]) %>%
  select(year, inflation_adjustment_factor)

# write inflation adjustment factors
write.csv(file = here("Confidential", "hindcast_output", output_subdir_name, "tables", "inflation_adjustment.csv"), x = gdp_defl)

# plot inflation adjustment factors
gdp_defl %>% ggplot(aes(x = as.factor(year), y = inflation_adjustment_factor)) + geom_point()
ggsave(here("Confidential", "hindcast_output", output_subdir_name, "figures", "inflation_adjustment.png"))

# clean up
rm(fred_gdpdefl)
```

The reference year for inflation adjustment is `r max(gdp_defl$year)`.

## Transform data

Transform the joined, cleaned, interpolated VMS and fish ticket data:

1. Filter for dungeness crab related records.
2. Add temporal columns.
3. Adjust revenue for inflation with data from FRED.

Some commonly used acronyms for variable naming in the code include:

* `dcrb` dungeness crab
* `rev` revenue
* `lbs` landings
* `VMS` vessel monitoring system
* `afi` adjusted for inflation

```{r define-filters}
# define filters
target_rev <- "DCRB"         # revenue target
target_lbs <- "DCRB"         # landings target
min_depth <- 0               # minimum depth in meters
max_depth <- -150            # maximum depth in meters
min_speed <- 0               # minimum speed in m/s
max_speed <- 4.11556         # maximum speed in m/s (4.11556 m/s = 8 knots)
crab_year_start <- 11        # month defines start of crab year
winter_months <- c("November", "December", "January", "February", "March") # determine Winter or Spring-Summer season
```

```{r transform-ticket-data}
# apply same filters as VMS dataframe
dcrb_ticket_df <- ticket_df %>%
  # add temporal columns
  mutate(
    year_numeric = year(date),
    month_numeric = month(date),
    week_numeric = week(date),
    day_numeric = yday(date),
    month_factor = month(date, label = TRUE, abbr = FALSE),
    year_month_character = paste0(year(date),"_", substr(ymd(date), 6, 7)),
    crab_year_character = ifelse(month_numeric >= crab_year_start, 
                                 paste0(year_numeric, "_", 1+year_numeric),
                                 paste0(year_numeric-1, "_", year_numeric)),
    season_character = as.character(ifelse(month_factor %in% winter_months, "Winter", "Spring-Summer")),
    year_month_date = ym(year_month_character)
  ) %>%
  # apply filters
  filter(TARGET_rev == target_rev | TARGET_lbs == target_lbs) %>%
  # join inflation adjustment factor and adjust revenue
  left_join(gdp_defl, by = join_by(year_numeric == year)) %>%
  mutate(DCRB_revenue_afi = DCRB_revenue / inflation_adjustment_factor) %>%
  # select columns
  dplyr::select(
    # identifiers
    Rec_ID,           # fish ticket ID
    drvid,            # vessel ID
    pacfin_port_code, # port ID
    port_group_code,  # port group ID
    agency_code,      # agency code
    # temporal fields
    date,
    year_month_date,
    crab_year_character,
    year_month_character,
    month_factor,
    year_numeric,
    month_numeric,
    week_numeric,
    day_numeric,
    # vessel length
    FINAL_LENGTH,
    # dungeness crab fields
    DCRB_lbs,
    DCRB_revenue_afi
  ) %>%
  # de-duplicate records
  distinct()

# take a peek at the resulting dataframe
glimpse(dcrb_ticket_df)
```

```{r}
# count total records, trips and years
n_records <- nrow(dcrb_ticket_df)
n_trips   <- n_distinct(dcrb_ticket_df$Rec_ID)
n_years   <- n_distinct(dcrb_ticket_df$year_numeric)
```

The Dungeness crab fish ticket dataframe has `r n_records` records (fish tickets), `r n_trips` distinct trips (fish tickets), across `r n_years` years.

There are more records than trips due to the vessel registration processing code including the lookback window data in step 2 of the pipeline. I looked at some examples of duplicates, and they occur for tickets within the lookback window - for example, a ticket landed on Dec. 28, 2014 is processed in the 2014 and 2015 runs of the pipeline for vessel registration. I suspect this could be fixed in the pipeline itself, but I'm leaving it be for now.

This is fixed here in the plotting code by removing duplicates when one length is NA, and I didn't see any duplication within the VMS data.

```{r}
# identify which records need to be de-duplicated, by finding RecIDs with 2 records, 1 of which has NA length
qa_df <- dcrb_ticket_df %>% 
  group_by(Rec_ID) %>%
  summarize(n = n(),
            na_length = sum(is.na(FINAL_LENGTH))) %>%
  mutate(remove_na = (na_length == 1) & (n == 2)) %>%
  arrange(desc(n))
glimpse(qa_df)

# how many records need de-duplication (have 2 records, 1 of which has NA length)?
qa_df %>% group_by(n, na_length, remove_na) %>% summarise(n_records = n()) %>% arrange(desc(n_records)) # 7499 records

# join back to dcrb_ticket_df
qa_dcrb_ticket_df <- dcrb_ticket_df %>%
  left_join(qa_df, by = join_by(Rec_ID)) %>%
  filter(!(remove_na & is.na(FINAL_LENGTH)))

# count total records, trips and years
n_qa_records <- nrow(qa_dcrb_ticket_df)
n_qa_trips   <- n_distinct(qa_dcrb_ticket_df$Rec_ID)
n_qa_years   <- n_distinct(qa_dcrb_ticket_df$year_numeric)
```

The QA'ed Dungeness crab fish ticket dataframe has `r n_records` records (fish tickets), `r n_trips` distinct trips (fish tickets), across `r n_years` years. Now there are no duplicate fish tickets.

