---
title: "Hindcasts of California Dungeness crab fishing activity, 2011-2023"
author: "Brooke Hawkins"
date: "`r Sys.Date()`"
output: html_document
---

## Purpose
* Integrate interpolated VMS and fish ticket data to produce time series, rasters, and maps of fishing activity, landed weight, and revenue.
Deliverable:
* Monthly maps of fishing activity; tables summarizing monthly fishing activity

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prep data

```{r import-libraries}
library(here)
library(readr)
library(tidyverse)
library(sf)
library(rnaturalearth)
library(viridis)
```

I'm starting with one year and one season, I will extend to more years once I like the output format.

```{r load-data}
# load RDS of joined, cleaned, interpolated VMS and fish ticket data as a dataframe
vms_df <- read_rds(here('Confidential', 'processed', 'matched', 'interpolation', '2014_interpolated.rds'))

# load 5km grid shape file as a simple features object
grid_5km <- read_sf(here('GIS_layers', 'master_5km_grid_tmer.shp'))

# join VMS and fish ticket data to grid
vms_df <- vms_df %>%
  st_as_sf(coords = c('LON', 'LAT'), crs=4326) %>%
  st_transform(st_crs(grid_5km)) %>%
  st_join(grid_5km) %>%
  st_set_geometry(NULL)
```

Some commonly used acronyms in variable naming are:

* `dcrb` dungeness crab
* `rev` revenue
* `lbs` pounds
* `VMS` vessel monitoring system

```{r transform-data}
# define filters
target_rev <- "DCRB"         # revenue target
target_lbs <- "DCRB"         # landings target
state_agency_code <- "C"     # landings brought to California ports
min_depth <- 0               # minimum depth in meters
max_depth <- -150            # maximum depth in meters
min_speed <- 0               # minimum speed in m/s
max_speed <- 4.11556         # maximum speed in m/s (4.11556 m/s = 8 knots)
crab_year_start <- 11        # month defines start of crab year
crab_years <- c("2014_2015") # crab years to include
winter_months <- c("November", "December", "January", "February", "March") # determine Winter or Spring-Summer season

# transform data
dcrb_df <- vms_df %>%
  # add temporal columns
  mutate(
    year = lubridate::year(westcoastdate_notime),
    month = lubridate::month(westcoastdate_notime, label=TRUE, abbr=FALSE),
    month_numeric = month(westcoastdate_notime),
    year_month = paste0(lubridate::year(westcoastdate_notime),"_", substr(lubridate::ymd(westcoastdate_notime), 6, 7)),
    crab_year = ifelse(month_numeric >= crab_year_start, paste0(year, "_", 1+year), paste0(year-1, "_", year)),
    season = as.character(ifelse(month %in% winter_months, "Winter", "Spring-Summer")),
    week_of_year = week(westcoastdate_notime),
    day_of_year = yday(westcoastdate_notime)
  ) %>%
  # apply filters
  filter(TARGET_rev == target_rev | TARGET_lbs == target_lbs) %>%
  filter(agency_code == state_agency_code) %>%
  filter(NGDC_M <= min_depth & NGDC_M >= max_depth) %>% # TODO should this be for WM_NGDC_M instead?
  filter(avg_speed_recalc <= max_speed & avg_speed_recalc >= min_speed) %>% 
  filter(crab_year %in% crab_years) %>%
  # select columns
  dplyr::select(
    # identifiers
    Rec_ID,           # fish ticket ID
    VMS_RECNO,        # VMS ping ID
    drvid,            # vessel ID
    pacfin_port_code, # port ID
    port_group_code,  # port group ID
    GRID5KM_ID,       # grid cell ID
    # temporal fields
    westcoastdate,
    westcoastdate_notime,
    crab_year, 
    season,
    year,
    year_month,
    month, 
    month_numeric,
    week_of_year,
    day_of_year,
    # vessel length
    FINAL_LENGTH,
    # dungeness crab fields
    DCRB_lbs,
    DCRB_revenue
  )

# count total records, trips and years
n_records <- nrow(vms_df)
n_trips   <- n_distinct(vms_df$Rec_ID)
n_years   <- n_distinct(lubridate::year(vms_df$westcoastdate_notime))

# take a peek at the resulting dataframe
glimpse(dcrb_df)
```

The dungeness crab dataframe has `r n_records` records (interpolated VMS pings), `r n_trips` trips (fish tickets), across `r n_years` years.

I need to check on rescaled vs. normalized.

```{r summarize-fishing-activity}
# summarize trip-level attributes
trip_df <- dcrb_df %>%
  group_by(Rec_ID) %>%
  summarise(trip_n_vms_records = n(),
            trip_start = min(westcoastdate),
            trip_end = max(westcoastdate))

# join trip-level attributes back to dungeness crab dataframe
dcrb_trip_df <- left_join(dcrb_df, trip_df, by="Rec_ID") %>%
  mutate(
    dcrb_lbs_per_vms_record     = DCRB_lbs / trip_n_vms_records,
    dcrb_rev_per_vms_record     = DCRB_revenue / trip_n_vms_records,
    dcrb_vessels_per_vms_record = 1 / trip_n_vms_records
  )

# create monthly gridded summary
dcrb_5km_summary_df <- dcrb_trip_df %>%
  group_by(
    # grid cell ID, makes this a gridded summary
    GRID5KM_ID,
    # temporal columns, makes this a monthly summary
    year,
    crab_year,
    year_month,
    season,
    month,
    month_numeric
  ) %>%
  # sum landings, revenue; count unique vessels and VMS records
  summarise(
    dcrb_lbs = sum(dcrb_lbs_per_vms_record),
    dcrb_rev = sum(dcrb_rev_per_vms_record),
    n_vms_records = n(),
    n_unique_vessels = n_distinct(drvid)
  ) %>% 
  ungroup() %>%
  # rescale fishing effort from 0 to 1
  mutate(
    normalized_n_vms_records = as.vector(scale(n_vms_records, center=min(n_vms_records), scale=diff(range(n_vms_records)))),
    normalized_n_vms_records = ifelse(
      normalized_n_vms_records == 0,
      0.5 * min(normalized_n_vms_records[normalized_n_vms_records != min(normalized_n_vms_records)]),
      normalized_n_vms_records
    ),
    rescaled_n_vms_records = as.vector(scale(n_vms_records, center=0, scale=max(n_vms_records)))
  )

# compare ranges of normalized vs. rescaled
print(summary(dcrb_5km_summary_df$rescaled_n_vms_records))
print(summary(dcrb_5km_summary_df$normalized_n_vms_records))

# join geometry from 5km grid to gridded fishing summary
dcrb_5km_summary_sf <- dcrb_5km_summary_df %>%
  left_join(grid_5km, by=join_by(GRID5KM_ID)) %>%
  st_as_sf()
```

## Confidentiality filter

I'd like to do this one step earlier (to `_df` rather than `_sf`), and write the output with normalized VMS records to a CSV. I think there's a better way to summarize this, with n_vms_pings as records rather than grid cell months.

```{r}
# create a non-confidential version of gridded fishing summary
dcrb_5km_summary_confidential_sf <- dcrb_5km_summary_sf %>%
  filter(n_unique_vessels >= 3)

# summarize how much data is dropped
# get the number of records
n_drop_confidential <- dim(dcrb_5km_summary_sf)[1] - dim(dcrb_5km_summary_confidential_sf)[1]
# calculate the number of records, and convert to a percent as a string
percent_drop_confidential <- substr(as.character(n_drop_confidential / dim(dcrb_5km_summary_sf)[1] * 100), 1, 5)
```

The non-confidential data has `r n_drop_confidential` (`r percent_drop_confidential`%) fewer records, where grid cells had <3 unique vessels in a given month.

## Map data

```{r maps}
# load west coast states simple features object
west_coast_states <- rnaturalearth::ne_states(country='United States of America', returnclass='sf') %>% 
  filter(name %in% c('California','Oregon','Washington','Nevada')) %>% 
  st_transform(st_crs(grid_5km))

# set bounding box 
bbox <- st_bbox(dcrb_5km_summary_confidential_sf)

# basic plot
map_density <- ggplot() +
  # plot background
  geom_sf(data=west_coast_states, fill='gray80') +
  # plot fishing effort
  geom_sf(data=dcrb_5km_summary_confidential_sf, aes(fill=log10(n_vms_records))) +
  # label plot
  labs(fill="log10(n_vms_records) per 5x5 cell") +
  # aesthetic changes
  xlim(bbox[1], bbox[3]) + ylim(bbox[2], bbox[4]) +
  scale_fill_viridis() +
  theme(axis.text.x=element_text(angle=45, vjust=1, hjust=1),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank(),
        legend.position="bottom")
ggsave(filename=here("Confidential", "figures", "sample_fishing_effort_map.png"))
# see result
map_density

# another basic plot
map_density <- ggplot() +
  # plot background
  geom_sf(data=west_coast_states, fill='gray80') +
  # plot fishing effort
  geom_sf(data=dcrb_5km_summary_confidential_sf, aes(fill=log10(rescaled_n_vms_records))) +
  # label plot
  labs(fill="log10(rescaled_n_vms_records) per 5x5 cell") +
  # aesthetic changes
  xlim(bbox[1], bbox[3]) + ylim(bbox[2], bbox[4]) +
  scale_fill_viridis() +
  theme(axis.text.x=element_text(angle=45, vjust=1, hjust=1),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank(),
        legend.position="bottom")
ggsave(filename=here("Confidential", "figures", "sample_rescaled_fishing_effort_map.png"))
# see result
map_density

# another basic plot
map_density <- ggplot() +
  # plot background
  geom_sf(data=west_coast_states, fill='gray80') +
  # plot fishing effort
  geom_sf(data=dcrb_5km_summary_confidential_sf, aes(fill=log10(normalized_n_vms_records))) +
  # label plot
  labs(fill="log10(normalized_n_vms_records) per 5x5 cell") +
  # aesthetic changes
  xlim(bbox[1], bbox[3]) + ylim(bbox[2], bbox[4]) +
  scale_fill_viridis() +
  theme(axis.text.x=element_text(angle=45, vjust=1, hjust=1),
        axis.ticks.x=element_blank(),
        axis.ticks.y=element_blank(),
        legend.position="bottom")
ggsave(filename=here("Confidential", "figures", "sample_normalized_fishing_effort_map.png"))
# see result
map_density
```

## Summarize data

I need to update this to use a confidential version. Or all the calculations are wrong anyway, so might be a moot point.

```{r}
# define columns and functions to summarize in table
colnames_vector <- c('n_vms_records', 'normalized_n_vms_records', 'rescaled_n_vms_records')
function_vector <- c('length', 'min', 'mean', 'median', 'max', 'IQR')

# summarize in a for loop for columns in column name vector c_vector
summary_table <- rbind(
  summarise_at(dcrb_5km_summary_df, colnames_vector, get(function_vector[1])),
  summarise_at(dcrb_5km_summary_df, colnames_vector, get(function_vector[2])),
  summarise_at(dcrb_5km_summary_df, colnames_vector, get(function_vector[3])),
  summarise_at(dcrb_5km_summary_df, colnames_vector, get(function_vector[4])),
  summarise_at(dcrb_5km_summary_df, colnames_vector, get(function_vector[5])),
  summarise_at(dcrb_5km_summary_df, colnames_vector, get(function_vector[6]))
)

# reformat table
summary_table <- cbind(
  # add metric name as column
  metric = function_vector,
  summary_table
) %>% 
  # turn metric name into rowname
  column_to_rownames('metric') %>%
  # transpose result
  t()

# write result
write.csv(file=here("Confidential", "tables", "sample_summary_table.csv"), x=summary_table)

# see result
summary_table
```


