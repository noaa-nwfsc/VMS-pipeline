---
title: "Overlay VMS points grid of choice and calcailate value of each 5km x 5km grid cell per year for dungeness crab"
output: 
  html_document:
    toc: true
    toc_float: true
---

### Set up

Attribute the VMS and fish ticket pipeline output for dungeness crab to each grid cell, then summarize for two baseline periods and one implementation period. Created for CDFW data request by Oct. 1, 2024.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(sf)
library(here)
library(knitr)
library(lubridate)
library(glue)
library(readr)
library(rnaturalearth) # for mapping states
library(viridis) # for good color scales
```

### Import data

Load VMS pings with fish tickets for all years. Output is from Blake, run for dungeness crab on Sept. 17, 2024.

```{r import all}
# clear workspace of everything but 5km grid
rm(list=setdiff(ls(),'grd'))

# load 2014-2023 fish ticket and VMS data
vms_all <- read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2014_matched_filtered_withFTID_length.rds')) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2015_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2016_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2017_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2018_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2019_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2020_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2021_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2022_matched_filtered_withFTID_length.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'matched', 'filtering', '2023_matched_filtered_withFTID_length.rds')))

# take a look at imported features
# can change back to glimpse for example records
names(vms_all)
# check all years are present
unique(year(vms_all$date))
```

### Match VMS pings and fish tickets to grid cells

Load 5km grid. I suspect there's some redundancy here in loading and joining the grid, but I've left it as is for now.

```{r}

# load 5x5 grid shapefile
grd <- read_sf(here('GIS_layers', 'master_5km_grid_tmer.shp'))

# convert VMS to spatial object
pt <- proc.time()
vms_all_sf <- vms_all %>%
  st_as_sf(coords= c('LON','LAT'), crs=4326) %>% 
  # then, convert to planar projection to match the grid
  st_transform(st_crs(grd))
x <- proc.time() - pt
```

Took `r round(x[3]/60,2)` minutes to do the conversion. Now for the join...

```{r join VMS with spatial object to grid}
# do the join
pt <- proc.time()
vms_all_grd_match <- vms_all_sf %>%
  st_join(grd)

# explore output
names(vms_all_grd_match)

# check timing
x <- proc.time() - pt
```

The join took `r round(x[3]/60,2)` minutes.

### Write joined data

```{r}
# save without geometry while still including grid cell ID
vms_all_grd_match %>% 
  st_set_geometry(NULL) %>% 
  write_rds(here('Confidential', 'processed', 'interim', 'vms_all_w_grd_5km.rds'))

# load version without geometry with grid cell ID written above
vms_all_grd_match <- read_rds(here('Confidential', 'processed', 'interim', 'vms_all_w_grd_5km.rds'))
names(vms_all_grd_match)
```

### Filter data and add date columns

Now filter the data based on control variables below: dungeness crab target, landed in California, depth <= 150m, and vessel speeds <= 4 knots.
Then add date columns and select subset of columns.

Notes:

* *crab_year* is Nov.-Oct. (e.g. Nov. 2019 to Oct. 2020 for 2019_2020), rather than the precise dates of the crab fishing season.
* *agency_code* filters for VMS pings joined to fish tickets that were landed in California. You can see in the map at the end of the file this means some pings extend beyond California.
* *removal_type* to filter for commercial landings is not included here, so personal take is included in *DCRB_lbs*. This does not impact *DCRB_VMS_pings* or *DCRB_rev*.

```{r filter fishing data}

# set filter parameters
state_agency_code = "C" # filter for landings brought to California ports
target_rev <- "DCRB" # I suspect this filter is redundant since Blake ran the pipeline for only DCRB, but I left it for now
target_lbs <- "DCRB" # again, I suspect this filter is redundant, but left it for now
winter_months <- c("November", "December", "January", "February", "March") # used to set season as Winter or Spring-Summer
min_depth <- 0
max_depth <- -150  # filter for 0-150 M depth
max_speed <- 4.11556 # units of m/s. 4.11556m/s = 8knots (4DCRB) and 1.54333 m/s = 3 knots (4CHNK)
min_speed <- 0 # units = m/s

# set fishing seasons to include
crab_years_to_vis = c("2014_2015", "2015_2016", "2016_2017", "2017_2018", "2018_2019",
                      "2019_2020", "2020_2021", "2021_2022", "2022_2023")

# filter data, add year/season columns, and select columns for analysis
dcrb_vms_tix_analysis <- vms_all_grd_match %>%
  filter(agency_code == state_agency_code) %>%
  filter(TARGET_rev == target_rev | TARGET_lbs == target_lbs) %>%
  filter(NGDC_M <= min_depth & NGDC_M >= max_depth) %>%
  filter(avg_speed_recalc <= max_speed & avg_speed_recalc >= min_speed) %>%
  mutate(
    year = lubridate::year(westcoastdate_notime),
    year_month = paste0(lubridate::year(westcoastdate_notime),"_", substr(lubridate::ymd(westcoastdate_notime),6,7)),
    # substr() ensures month is a 2 digit value, e.g. February is "02" not "2"
    month = lubridate::month(westcoastdate_notime, label=TRUE, abbr = FALSE),
    month_as_numeric = month(westcoastdate_notime),
    season = as.character(ifelse(month %in% winter_months, "Winter", "Spring-Summer")),
    crab_year = ifelse(
      month_as_numeric >= 11, paste0(year, "_", 1+year), paste0(year-1, "_", year)
    )
  ) %>%
  filter(crab_year %in% crab_years_to_vis) %>%
  dplyr::select(
      GRID5KM_ID, # grid cell ID
      Rec_ID, # fish ticket ID
      VMS_RECNO, # VMS ping ID
      drvid, # vessel ID
      FINAL_LENGTH,
      westcoastdate,
      westcoastdate_notime,
      year,
      crab_year, 
      year_month,
      month, 
      month_as_numeric,
      season,
      pacfin_port_code, 
      port_group_code, 
      NGDC_M, # depth
      TARGET_lbs, # target species by weight (filtered to "DCRB")
      TARGET_rev, # target species by revenue (filtered to "DCRB")
      DCRB_lbs, # dungeness crab catch weight
      DCRB_revenue # dungeness crab catch revenue
    )

# take a look at transformed data
names(dcrb_vms_tix_analysis)

# check all crab years present
unique(dcrb_vms_tix_analysis$crab_year)
```

### Distribute $ and lbs to grid cells and normalize pings

Distribute rev and lbs to grid cells. Normalize VMS pings by year-month and grid cell.

Adjust ping rate with a monthly factor for before and after April 1, 2020, when OLE increased ping rate from 1x/hour to 4x/hour.

```{r distribute $ and lbs to cells, and adjust ping rate}

# set the start date for ping rate increase to April 1, 2020
ping_rate_increase_date <- ymd(20200401)

# calculate a monthly ping rate adjustment factor
# 1. calculate avg. pings per vessel before and after ping rate increase date
pre_post_ping_rate_increase <- dcrb_vms_tix_analysis %>% 
  filter(crab_year %in% crab_years_to_vis) %>%
  mutate(ping_rate_period = if_else(westcoastdate_notime < ping_rate_increase_date,
                                    "pre_ping_rate_increase",
                                    "post_ping_rate_increase")) %>% 
  group_by(ping_rate_period, month) %>%
  summarise(pings_per_vessel = n() / n_distinct(drvid))
# 2. calculate adjustment factor by dividing post_ping_rate_increase by pre_ping_rate_increase
# the result has one correction factor per month
ping_rate_adjustment_factor <- pre_post_ping_rate_increase %>% 
  pivot_wider(names_from = ping_rate_period, values_from = pings_per_vessel) %>%
  mutate(ping_rate_adjustment = post_ping_rate_increase / pre_ping_rate_increase) %>%
  arrange(month)

# create new columns that attribute pings, lbs, and $ from each fish ticket 
# across all VMS pings matched to that ticket

# total records per trip (total number of VMS records associated with each fish ticket)
# one record = one fish ticket
VMSrecords_per_trip <- dcrb_vms_tix_analysis %>%
  group_by(Rec_ID) %>%
  summarise(trip_VMSrecords = n(),
            trip_start = min(westcoastdate),
            trip_end = max(westcoastdate),
            trip_duration_hours = if_else(as.numeric(trip_end - trip_start, units = 'hours') > 0,
                                          as.numeric(trip_end - trip_start, units = 'hours'),
                                          1),
            avg_trip_ping_rate = trip_VMSrecords / trip_duration_hours,
            .groups = 'drop')

# join total records per trip to VMS and fish ticket data; adjust ping rate; calculate vessels, lbs, and $ per VMS ping
dcrb_vms_tix_analysis_TripInfo <- left_join(VMSrecords_per_trip, dcrb_vms_tix_analysis, by="Rec_ID") %>%
  left_join(ping_rate_adjustment_factor, by="month") %>%
  mutate(
    ping_rate_adjustment_factor = case_when(
      is.na(ping_rate_adjustment) ~ 1, # if there are any NAs (e.g. Sept. and Oct. only have data in either pre- or post-ping-rate-increase), no adjustment
      westcoastdate_notime < ping_rate_increase_date ~ 1, # for pre-ping-rate-increase, no adjustment
      westcoastdate_notime >= ping_rate_increase_date ~ ping_rate_adjustment # for post-ping-rate-increase, adjust
    ),
    trip_VMSrecords_adjusted = trip_VMSrecords / ping_rate_adjustment_factor, # adjusted trip-level pings
    VMSrecords_adjusted = 1 / ping_rate_adjustment_factor, # adjusted ping-level pings (e.g. for 1 ping with ping_rate_adjustment_factor = 2, this value is 0.5; count it as a half of a ping)
    VMSrecords_adjusted_trip = 1 / avg_trip_ping_rate, # adjusted record-level pings (e.g. for 1 ping from trip with 4 pings per hour, this value is 0.25)
    DCRB_lbs_per_VMSlocation = DCRB_lbs / trip_VMSrecords,
    DCRB_rev_per_VMSlocation = DCRB_revenue / trip_VMSrecords,
    DCRB_Vessels_per_VMSlocation = 1 / trip_VMSrecords
  )
names(dcrb_vms_tix_analysis_TripInfo)

# summarize and normalize fishery effort at year, month and grid cell level
# based on Jameal's prep_data_for_scenario_df_function.R
dcrb_year_month_5km_df <- dcrb_vms_tix_analysis_TripInfo %>%
  group_by(crab_year, year, year_month, month_as_numeric, month, GRID5KM_ID) %>%
  summarise(
    DCRB_lbs = sum(DCRB_lbs_per_VMSlocation),
    DCRB_rev = sum(DCRB_rev_per_VMSlocation),
    DCRB_VMS_pings = n(),
    DCRB_VMS_pings_adjusted = sum(VMSrecords_adjusted),
    DCRB_VMS_pings_adjusted_trip = sum(VMSrecords_adjusted_trip),
    DCRB_Vessels = sum(DCRB_Vessels_per_VMSlocation),
    Unique_DCRB_Vessels = length(unique(as.character(drvid)))
  ) %>%
  ungroup() %>%
  mutate(
    # rescale pings to 0-1
    normalized_DCRB_VMS_pings = as.vector(scale(DCRB_VMS_pings, center = min(DCRB_VMS_pings), scale = diff(range(DCRB_VMS_pings)))),
    # above rescaling converts 1 ping to 0, so change it so that 1 ping, after re-scaling, has a scaled value equal to one half of the rescaled value of 2 pings
    normalized_DCRB_VMS_pings = ifelse(
      normalized_DCRB_VMS_pings == 0, 
      0.5 * min(normalized_DCRB_VMS_pings[normalized_DCRB_VMS_pings != min(normalized_DCRB_VMS_pings)]),
      normalized_DCRB_VMS_pings
    ),
    # rescale adjusted pings to 0-1
    normalized_adjusted_DCRB_VMS_pings = as.vector(scale(DCRB_VMS_pings_adjusted, center = min(DCRB_VMS_pings_adjusted), scale = diff(range(DCRB_VMS_pings_adjusted)))),
    # above rescaling converts mininmum adjusted ping to 0, so change the minimum scaled value to one half of the rescaled value of the 2nd lowest adjusted ping value
    normalized_adjusted_DCRB_VMS_pings = ifelse(
      normalized_adjusted_DCRB_VMS_pings == 0, 
      0.5 * min(normalized_adjusted_DCRB_VMS_pings[normalized_adjusted_DCRB_VMS_pings != min(normalized_adjusted_DCRB_VMS_pings)]),
      normalized_adjusted_DCRB_VMS_pings
    ),
    # rescale adjusted trip pings to 0-1
    normalized_adjusted_trip_DCRB_VMS_pings = as.vector(scale(DCRB_VMS_pings_adjusted_trip, center = min(DCRB_VMS_pings_adjusted_trip), scale = diff(range(DCRB_VMS_pings_adjusted_trip)))),
    # above rescaling converts mininmum adjusted ping to 0, so change the minimum scaled value to one half of the rescaled value of the 2nd lowest adjusted ping value
    normalized_adjusted_trip_DCRB_VMS_pings = ifelse(
      normalized_adjusted_trip_DCRB_VMS_pings == 0, 
      0.5 * min(normalized_adjusted_trip_DCRB_VMS_pings[normalized_adjusted_trip_DCRB_VMS_pings != min(normalized_adjusted_trip_DCRB_VMS_pings)]),
      normalized_adjusted_trip_DCRB_VMS_pings
    )
  )

# save interim outputs
write_rds(dcrb_vms_tix_analysis_TripInfo, here::here('Confidential', 'processed', 'interim', 'dcrb_vms_tix_analysis_TripInfo.rds'))
write_rds(dcrb_year_month_5km_df, here::here('Confidential', 'processed', 'interim', 'dcrb_year_month_5km_df.rds'))

# visualize distribution of VMS pings
dcrb_year_month_5km_df %>%
  ggplot(aes(DCRB_VMS_pings)) + geom_histogram(binwidth=5)
print(range(dcrb_year_month_5km_df$DCRB_VMS_pings))

# visualize distribution of adjusted VMS pings
dcrb_year_month_5km_df %>%
  ggplot(aes(DCRB_VMS_pings_adjusted)) + geom_histogram(binwidth=5)
print(range(dcrb_year_month_5km_df$DCRB_VMS_pings_adjusted))

# visualize distribution of adjusted trip VMS pings
dcrb_year_month_5km_df %>%
  ggplot(aes(DCRB_VMS_pings_adjusted_trip)) + geom_histogram(binwidth=5)
print(range(dcrb_year_month_5km_df$DCRB_VMS_pings_adjusted_trip))

# visualize distribution of normalized VMS pings
dcrb_year_month_5km_df %>%
  ggplot(aes(normalized_DCRB_VMS_pings)) + geom_histogram(binwidth=0.01)
print(range(dcrb_year_month_5km_df$normalized_DCRB_VMS_pings))

# visualize distribution of normalized adjusted VMS pings
dcrb_year_month_5km_df %>%
  ggplot(aes(normalized_adjusted_DCRB_VMS_pings)) + geom_histogram(binwidth=0.01)
print(range(dcrb_year_month_5km_df$normalized_adjusted_DCRB_VMS_pings))

# visualize distribution of normalized adjusted trip VMS pings
dcrb_year_month_5km_df %>%
  ggplot(aes(normalized_adjusted_trip_DCRB_VMS_pings)) + geom_histogram(binwidth=0.01)
print(range(dcrb_year_month_5km_df$normalized_adjusted_trip_DCRB_VMS_pings))
```

### Create summaries for Heather

* *Baseline 2014-2019* includes the start of Nov. 2014 to the end of Oct. 2019.
* *Baseline 2017-2019* includes the start of Nov. 2017 to the end of Oct. 2019.
* *Implementation 2019-2023* includes the start of Nov. 2019 to the end of Oct. 2023.

For baseline periods, each record represents one grid cell for one month, across all years. Fishing effort measured by # of pings is averaged across years for a given month. Note that the # of unique vessels is the minimum for that grid cell and month in any year, let me know if I should update this.

For implementation period, each record represents one grid cell for one month in one year. 

```{r create summaries}

# set baseline and implementation years
baseline_2014_2019_crab_years <- c("2014_2015", "2015_2016", "2016_2017", "2017_2018", "2018_2019")
baseline_2017_2019_crab_years <- c("2017_2018", "2018_2019")
implementation_2019_2023_crab_years <- c("2019_2020", "2020_2021", "2021_2022", "2022_2023")

# summarize baseline data (2014-2018) at monthly temporal grain and grid cell ID spatial grain
baseline_2014_2019 <- dcrb_year_month_5km_df %>%
  filter(crab_year %in% baseline_2014_2019_crab_years) %>%
  group_by(GRID5KM_ID, month, month_as_numeric) %>%
  summarise(
    # take average by summing across years and dividing by # years
    # use sum / length instead of mean, because grid cells with 0 pings have no records, rather than a record with '0'
    avg_DCRB_lbs = sum(DCRB_lbs) / length(baseline_2014_2019_crab_years),
    avg_DCRB_rev = sum(DCRB_rev) / length(baseline_2014_2019_crab_years),
    avg_DCRB_VMS_pings = sum(DCRB_VMS_pings) / length(baseline_2014_2019_crab_years),
    avg_normalized_DCRB_VMS_pings = sum(normalized_DCRB_VMS_pings) / length(baseline_2014_2019_crab_years),
    avg_DCRB_VMS_pings_adjusted = sum(DCRB_VMS_pings_adjusted) / length(baseline_2014_2019_crab_years),
    avg_normalized_adjusted_DCRB_VMS_pings = sum(normalized_adjusted_DCRB_VMS_pings) / length(baseline_2014_2019_crab_years),
    avg_DCRB_VMS_pings_adjusted_trip = sum(DCRB_VMS_pings_adjusted_trip) / length(baseline_2014_2019_crab_years),
    avg_normalized_adjusted_trip_DCRB_VMS_pings = sum(normalized_adjusted_trip_DCRB_VMS_pings) / length(baseline_2014_2019_crab_years),
    avg_DCRB_Vessels = sum(DCRB_Vessels) / length(baseline_2014_2019_crab_years),
    # take minimum unique DCRB vessels across years
    min_Unique_DCRB_Vessels = min(Unique_DCRB_Vessels),
    .groups = 'drop'
  )
# explore output
names(baseline_2014_2019)
summary(baseline_2014_2019$avg_DCRB_VMS_pings)
summary(baseline_2014_2019$avg_normalized_DCRB_VMS_pings)
summary(baseline_2014_2019$avg_DCRB_VMS_pings_adjusted)
summary(baseline_2014_2019$avg_normalized_adjusted_DCRB_VMS_pings)
summary(baseline_2014_2019$avg_DCRB_VMS_pings_adjusted_trip)
summary(baseline_2014_2019$avg_normalized_adjusted_trip_DCRB_VMS_pings)
sort(unique(baseline_2014_2019$month_as_numeric))
# write output
write_rds(baseline_2014_2019, here::here('Confidential', 'processed', 'summaries', 'baseline_2014_2019.rds'))

# summarize baseline data (2017-2018) at monthly temporal grain and grid cell ID spatial grain
baseline_2017_2019 <- dcrb_year_month_5km_df %>%
  filter(crab_year %in% baseline_2017_2019_crab_years) %>%
  group_by(GRID5KM_ID, month, month_as_numeric) %>%
  summarise(
    # take average by summing across years and dividing by # years
    # use sum / length instead of mean, because grid cells with 0 pings have no records, rather than a record with '0'
    avg_DCRB_lbs = sum(DCRB_lbs) / length(baseline_2017_2019_crab_years),
    avg_DCRB_rev = sum(DCRB_rev) / length(baseline_2017_2019_crab_years),
    avg_DCRB_VMS_pings = sum(DCRB_VMS_pings) / length(baseline_2017_2019_crab_years),
    avg_normalized_DCRB_VMS_pings = sum(normalized_DCRB_VMS_pings) / length(baseline_2017_2019_crab_years),
    avg_DCRB_Vessels = sum(DCRB_Vessels) / length(baseline_2017_2019_crab_years),
    avg_DCRB_VMS_pings_adjusted = sum(DCRB_VMS_pings_adjusted) / length(baseline_2017_2019_crab_years),
    avg_normalized_adjusted_DCRB_VMS_pings = sum(normalized_adjusted_DCRB_VMS_pings) / length(baseline_2017_2019_crab_years),
    avg_DCRB_VMS_pings_adjusted_trip = sum(DCRB_VMS_pings_adjusted_trip) / length(baseline_2017_2019_crab_years),
    avg_normalized_adjusted_trip_DCRB_VMS_pings = sum(normalized_adjusted_trip_DCRB_VMS_pings) / length(baseline_2017_2019_crab_years),
    # take minimum unique DCRB vessels across years
    min_Unique_DCRB_Vessels = min(Unique_DCRB_Vessels),
    .groups = 'drop'
  )
# explore output
names(baseline_2017_2019)
sort(unique(baseline_2017_2019$month_as_numeric))
summary(baseline_2017_2019$avg_DCRB_VMS_pings)
summary(baseline_2017_2019$avg_normalized_DCRB_VMS_pings)
summary(baseline_2017_2019$avg_DCRB_VMS_pings_adjusted_trip)
summary(baseline_2017_2019$avg_normalized_adjusted_trip_DCRB_VMS_pings)
# write output
write_rds(baseline_2017_2019, here::here('Confidential', 'processed', 'summaries', 'baseline_2017_2019.rds'))

# write real-time data (2019-2023) at yearly and monthly temporal grain and grid cell ID spatial grain
implementation_2019_2023 <- dcrb_year_month_5km_df %>%
  filter(crab_year %in% implementation_2019_2023_crab_years)
# explore output
names(implementation_2019_2023)
sort(unique(implementation_2019_2023$month_as_numeric))
summary(implementation_2019_2023$DCRB_VMS_pings)
summary(implementation_2019_2023$normalized_DCRB_VMS_pings)
summary(implementation_2019_2023$DCRB_VMS_pings_adjusted)
summary(implementation_2019_2023$normalized_adjusted_DCRB_VMS_pings)
summary(implementation_2019_2023$DCRB_VMS_pings_adjusted_trip)
summary(implementation_2019_2023$normalized_adjusted_trip_DCRB_VMS_pings)
# write output
write_rds(implementation_2019_2023, here::here('Confidential', 'processed', 'summaries', 'implementation_2019_2023.rds'))
```

### Map pings

For a common sense check, see how the baseline periods and implementation period fishing effort look on a map. Visualize average # of pings for baseline periods, and # of pings for implementation period.

```{r visualize on map}

# based on Owen's compare_hw_bh.R

# West coast, using the rnaturalearth package (for a background map)
coaststates <- ne_states(country='United States of America',returnclass = 'sf') %>% 
  filter(name %in% c('California','Oregon','Washington','Nevada')) %>% 
  # spatially transform to the same coordinate ref system as the 5k grid
  st_transform(st_crs(grd))

# join summary back to geometry by GRID5KM_ID
dcrb_year_month_5km_df_with_grid <- dcrb_year_month_5km_df %>% 
  left_join(grd, by = join_by(GRID5KM_ID)) %>%
  st_as_sf()

# set bounding box 
bbox <- st_bbox(dcrb_year_month_5km_df_with_grid)

# visualize VMS pings (no adjustment, no normalization) across all crab years
map_unadjusted_pings <- ggplot() +
  geom_sf(data = coaststates, fill = 'gray80') +
  geom_sf(data = dcrb_year_month_5km_df_with_grid, aes(fill = log10(DCRB_VMS_pings)), color = NA) +
  facet_grid(. ~ crab_year) +
  scale_fill_viridis() +
  xlim(bbox[1], bbox[3]) + ylim(bbox[2], bbox[4]) +
  labs(fill="log10(Pings) per 5x5 cell") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position="bottom")
map_unadjusted_pings
ggsave(filename = here::here("Confidential", "figures", "map_unadjusted_pings.png"),
       width = 10, height = 5)

# visualize VMS pings (tripwise adjustment, no normalization) across all crab years
map_adjusted_pings <- ggplot() +
  geom_sf(data = coaststates, fill = 'gray80') +
  geom_sf(data = dcrb_year_month_5km_df_with_grid, aes(fill = log10(DCRB_VMS_pings_adjusted_trip)), color = NA) +
  facet_grid(. ~ crab_year) +
  scale_fill_viridis() +
  xlim(bbox[1], bbox[3]) + ylim(bbox[2], bbox[4]) +
  labs(fill="log10(Adjusted Pings) per 5x5 cell") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position="bottom")
map_adjusted_pings
ggsave(filename = here::here("Confidential", "figures", "map_adjusted_pings.png"),
       width = 10, height = 5)

# visualize VMS pings (no adjustment, with normalization) across all crab years
map_unadjusted_normalized_pings <- ggplot() +
  geom_sf(data = coaststates, fill = 'gray80') +
  geom_sf(data = dcrb_year_month_5km_df_with_grid, aes(fill = log10(normalized_DCRB_VMS_pings)), color = NA) +
  facet_grid(. ~ crab_year) +
  scale_fill_viridis() +
  xlim(bbox[1], bbox[3]) + ylim(bbox[2], bbox[4]) +
  labs(fill="log10(Normalized Pings) per 5x5 cell") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position="bottom")
map_unadjusted_normalized_pings
ggsave(filename = here::here("Confidential", "figures", "map_unadjusted_normalized_pings.png"),
       width = 10, height = 5)

# visualize VMS pings (tripwise adjustment, with normalization) across all crab years
map_adjusted_normalized_pings <- ggplot() +
  geom_sf(data = coaststates, fill = 'gray80') +
  geom_sf(data = dcrb_year_month_5km_df_with_grid, aes(fill = log10(normalized_adjusted_trip_DCRB_VMS_pings)), color = NA) +
  facet_grid(. ~ crab_year) +
  scale_fill_viridis() +
  xlim(bbox[1], bbox[3]) + ylim(bbox[2], bbox[4]) +
  labs(fill="log10(Normalized Adjusted Pings) per 5x5 cell") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        legend.position="bottom")
map_adjusted_normalized_pings
ggsave(filename = here::here("Confidential", "figures", "map_adjusted_normalized_pings.png"),
       width = 10, height = 5)
```

### Visualize ping rate

At some point, the VMS ping rate increased from ~1/hour to ~1/15 minutes. As a result, in the time frame with the increased ping rate, fishing effort will look ~4x higher (when it's really just a change in sampling rate), and DCRB_lbs and DCRB_rev are spread over a higher resolution track (4x as many pings to attribute a single fish ticket to).

I'm visualizing this in two ways. 

1. Visualize time series of avg. pings per ticket tickets over time. I'm looking for an increase at a particular point in time, after which I will apply a correction for the increased ping rate. I also visualized number of tickets, just to explore for my own learning.
2. Visualize distribution of total and normalized pings per grid cell over time. Again, I'm looking for an increase at a particular point in time.

```{r check when ping rate increased}

# approach 1: look at avg. pings per ticket over time

# visualize average pings per ticket over time
avg_pings_per_ticket_over_time <- dcrb_vms_tix_analysis %>%
  group_by(westcoastdate_notime, Rec_ID) %>%
  summarise(trip_VMSrecords = n()) %>%
  ungroup() %>%
  group_by(westcoastdate_notime) %>%
  summarise(n_tickets = n(),
            avg_pings_per_ticket = mean(trip_VMSrecords))
# plot # pings and avg. pings per ticket vs. time, each point is one day
avg_pings_per_ticket_over_time %>% 
  pivot_longer(-westcoastdate_notime) %>%
  ggplot(aes(x = westcoastdate_notime, y = value)) +
    geom_point() +
    facet_grid(name ~ .)

# looks like the increase was in 2021, now find out which month...

# look at average pings per ticket over time in table
avg_pings_per_ticket_over_time <- dcrb_vms_tix_analysis %>%
  filter(year == 2021) %>%
  group_by(month, Rec_ID) %>%
  summarise(trip_VMSrecords = n()) %>%
  ungroup() %>%
  group_by(month) %>%
  summarise(n_tickets = n(),
            avg_pings_per_ticket = mean(trip_VMSrecords))
# plot # pings and avg. pings per ticket vs. time, each point is one month
avg_pings_per_ticket_over_time %>% 
  pivot_longer(-month) %>%
  ggplot(aes(x = month, y = value, color = name)) +
    geom_point() + 
    facet_grid(name ~ .)

# looks like the increase was in January, look for a specific day...

# look at average pings per ticket over time in table
avg_pings_per_ticket_over_time <- dcrb_vms_tix_analysis %>%
  filter(year == 2021 & month == 'January') %>%
  group_by(westcoastdate_notime, Rec_ID) %>%
  summarise(trip_VMSrecords = n()) %>%
  ungroup() %>%
  group_by(westcoastdate_notime) %>%
  summarise(n_tickets = n(),
            avg_pings_per_ticket = mean(trip_VMSrecords))
# plot # pings and avg. pings per ticket vs. time, each point is one day in Jan. 2021
avg_pings_per_ticket_over_time %>% 
  pivot_longer(-westcoastdate_notime) %>%
  ggplot(aes(x = westcoastdate_notime, y = value, color = name)) +
    geom_point() + geom_line() +
    facet_grid(name ~ .)

# looks like the increase was at the start of January 2021.

# approach 2: look at # pings and normalized # pings per grid cell over time
# 1 record = sum of pings per grid cell per year-month

# visualize distribution of pings in violin plot
dcrb_year_month_5km_df %>%
  ggplot(aes(x = factor(year), y = DCRB_VMS_pings)) + 
  geom_boxplot()

# see summary of pings by year
dcrb_year_month_5km_df %>%
  group_by(year) %>%
  summarise(
    min_DCRB_VMS_pings = min(DCRB_VMS_pings),
    median_DCRB_VMS_pings = median(DCRB_VMS_pings),
    mean_DCRB_VMS_pings = mean(DCRB_VMS_pings),
    max_DCRB_VMS_pings = max(DCRB_VMS_pings)
  )

# see summary of normalized pings by year
dcrb_year_month_5km_df %>%
  group_by(year) %>%
  summarise(
    min_normalized_DCRB_VMS_pings = min(normalized_DCRB_VMS_pings),
    median_normalized_DCRB_VMS_pings = median(normalized_DCRB_VMS_pings),
    mean_normalized_DCRB_VMS_pings = mean(normalized_DCRB_VMS_pings),
    max_normalized_DCRB_VMS_pings = max(normalized_DCRB_VMS_pings)
  )
```

Jameal shared that the ping rate increased 4x in April 2020 for 900/1200 vessels.

Look for a monthly factor to correct vessel ping rate. This is a rough/fast fix, and it is worth checking how sensitive cooccurrence metrics are based on this correction factor.

```{r quick plot - fish tickets and season length over years}
# is fishing effort (as # fish tickets / # days fishery open) consistent in the post-April 2020 period?

crab_years_to_vis = c("2014_2015", "2015_2016", "2016_2017", "2017_2018", "2018_2019",
                      "2019_2020", "2020_2021", "2021_2022", "2022_2023")

# how many days was the fishery open each season? how many fish tickets for each season?
# -"open" means there were VMS pings with fish tickets matched to them
# - crab_year represents a season and is defined earlier in this script as Nov. - Oct., it is not based on closures

# season length by year
n_fish_tickets_per_day_by_crab_year <- dcrb_vms_tix_analysis %>%
  filter(crab_year %in% crab_years_to_vis) %>%
  group_by(crab_year) %>%
  summarise(season_start_day = min(westcoastdate_notime),
            season_end_day = max(westcoastdate_notime),
            season_length = season_end_day - season_start_day,
            season_length_numeric = as.numeric(season_length, unit = 'days'),
            n_fish_tickets = n_distinct(Rec_ID),
            n_fish_tickets_per_season_day = n_fish_tickets / season_length_numeric)
# see table
n_fish_tickets_per_day_by_crab_year

# plot separately over time
plot_n_fish_tickets <- ggplot(n_fish_tickets_per_day_by_crab_year, aes(x = crab_year, y = n_fish_tickets, group = 1)) +
    geom_point() + geom_line() + ylim(0, max(n_fish_tickets_per_day_by_crab_year$n_fish_tickets))
plot_season_length <- ggplot(n_fish_tickets_per_day_by_crab_year, aes(x = crab_year, y = season_length, group = 1)) +
    geom_point() + geom_line() + ylim(0, max(n_fish_tickets_per_day_by_crab_year$season_length))
plot_n_fish_tickets_per_season_day <- ggplot(n_fish_tickets_per_day_by_crab_year, aes(x = crab_year, y = n_fish_tickets_per_season_day, group = 1)) +
    geom_point() + geom_line() + ylim(0, max(n_fish_tickets_per_day_by_crab_year$n_fish_tickets_per_season_day))
# give up and look at them individually...
plot_n_fish_tickets
plot_season_length
plot_n_fish_tickets_per_season_day
```

```{r quick plot - # vessels before and after ping rate increase (Apr. 2020)}

monthly_df <- dcrb_vms_tix_analysis_TripInfo %>% 
  filter(year >= 2018 & year <= 2022) %>%
  mutate(month_as_date = round_date(westcoastdate_notime, unit='month')) %>%
  group_by(year, month_as_date) %>%
  summarise(n_vessels = n_distinct(drvid),
            n_tickets = n_distinct(Rec_ID),
            n_pings = n())
  
monthly_df

monthly_df %>% 
  ggplot(aes(x=month_as_date, y=n_vessels, color = as.factor(year))) + geom_point() + geom_line(group=1) +
    theme(axis.text.x = element_text(angle = 300))

monthly_df %>% 
  ggplot(aes(x=month_as_date, y=n_tickets, color = as.factor(year))) + geom_point() + geom_line(group=1) +
    theme(axis.text.x = element_text(angle = 300))

monthly_df %>% 
  ggplot(aes(x=month_as_date, y=n_pings, color = as.factor(year))) + geom_point() + geom_line(group=1) +
    theme(axis.text.x = element_text(angle = 300))

```

```{r calculate monthly adjustment for before and after ping rate increase}
# set the start date for ping rate increase to April 1, 2020
ping_rate_increase_date <- ymd(20200401)

# set fishing seasons to include
crab_years_to_vis = c("2014_2015", "2015_2016", "2016_2017", "2017_2018", "2018_2019",
                      "2019_2020", "2020_2021", "2021_2022", "2022_2023")

# take a quick look at vessels, tickets, and pings per month across fishing seasons in analysis
dcrb_vms_tix_analysis_TripInfo %>% 
  filter(crab_year %in% crab_years_to_vis) %>%
  group_by(month) %>%
  summarise(n_vessels = n_distinct(drvid),
            n_tickets = n_distinct(Rec_ID),
            n_pings = n(),
            n_years = n_distinct(year),
            n_crab_years = n_distinct(crab_year))

# calculate the monthly ping rate per unique vessel before and after April 1, 2020
pre_post_ping_rate_increase <- dcrb_vms_tix_analysis_TripInfo %>%
  filter(crab_year %in% crab_years_to_vis) %>%
  mutate(ping_rate_period = if_else(westcoastdate_notime < ping_rate_increase_date,
                                    "pre_ping_rate_increase",
                                    "post_ping_rate_increase")) %>% 
  group_by(ping_rate_period, month) %>%
  summarise(pings_per_vessel = n() / n_distinct(drvid)) # (# of pings) / (# of unique vessels)
# I'm not sure if month comes from fish ticket or from VMS ping time
# for this use case, I don't want fish tickets split across months, so I want the month of the fish ticket or of the trip start
# that may mean the variable in group_by needs to change

# plot the rates
pre_post_ping_rate_increase %>%
  ggplot(aes(x=month, y=pings_per_vessel, fill = ping_rate_period)) + 
  geom_col(position='dodge') +
  theme(axis.text.x = element_text(angle = 300))

# calculate the correction factor by dividing post period / pre period
ping_rate_adjustment_factor <- pre_post_ping_rate_increase %>% 
  pivot_wider(names_from = ping_rate_period, values_from = pings_per_vessel) %>%
  mutate(ping_rate_correction = post_ping_rate_increase / pre_ping_rate_increase) %>%
  arrange(month)
# take a look
ping_rate_adjustment_factor

```

```{r quick plot - ping interval}
# each point = 1 VMS ping
ping_interval_df <- dcrb_vms_tix_analysis %>%
  group_by(Rec_ID) %>%
  arrange(westcoastdate) %>%
  mutate(
    next_time = lag(westcoastdate, 1),
    ping_interval_min = as.numeric(difftime(westcoastdate, next_time, units = 'mins')),
    ping_interval_hours = as.numeric(difftime(westcoastdate, next_time, units = 'hours'))
  )

ping_interval_df %>%
  group_by(crab_year) %>%
  summarise(min = min(ping_interval_hours, na.rm=TRUE),
            median = median(ping_interval_hours, na.rm=TRUE),
            mean = mean(ping_interval_hours, na.rm=TRUE),
            max = max(ping_interval_hours, na.rm=TRUE))

# look by year
ping_interval_df %>%
  ggplot(aes(x = as.factor(crab_year), y = ping_interval_hours)) + geom_boxplot() + ylim(c(0,2))

# look by month (expect shift in Sept. 2020 based on what Blake saw in a quick check in the raw VMS data)
ping_interval_df %>%
  filter(crab_year %in% c("2019_2020", "2020_2021")) %>%
  ggplot(aes(x = as.factor(year_month), y = ping_interval_hours)) + geom_boxplot() + ylim(c(0,2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# look by day
ping_interval_df %>%
  filter(year_month %in% c("2020_12", "2021_01")) %>%
  ggplot(aes(x = as.factor(westcoastdate_notime), y = ping_interval_hours)) + geom_boxplot() + ylim(c(0,2)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# I'm seeing the shift in ping rates between Dec. 30, 2020 and Jan. 7, 2021
```

```{r quick plot - pings / hour by trip and vessel hours}
# avg. ping rate summary
VMSrecords_per_trip %>%
  group_by(year(trip_start)) %>%
  summarise(min = min(avg_trip_ping_rate, na.rm=TRUE),
            median = median(avg_trip_ping_rate, na.rm=TRUE),
            mean = mean(avg_trip_ping_rate, na.rm=TRUE),
            max = max(avg_trip_ping_rate, na.rm=TRUE))

# avg. ping rate  boxplot
VMSrecords_per_trip %>%
  ggplot(aes(x=as.factor(year(trip_start)), y=avg_trip_ping_rate)) + geom_boxplot() + ylim(c(0,10))

# consistency in hours fishing across vessels from year to year?
VMSrecords_per_trip %>%
  group_by(trip_year = year(trip_start)) %>%
  summarise(total_vessel_hours = sum(trip_duration_hours))

# avg. ping rate histogram for before and after ping rate increase
ping_rate_increase_date <- ymd(20210101) # set to Jan. 1, 2021 based on plots above
VMSrecords_per_trip %>%
  mutate(ping_rate_period = if_else(
    trip_start >= ping_rate_increase_date, 
    "post ping rate increase", 
    "pre ping rate increase")
  ) %>%
  ggplot(aes(x = avg_trip_ping_rate, fill = ping_rate_period)) + 
  geom_histogram() + 
  xlim(c(0, 5)) + # limit to interesting data, ignoring a long tail here
  facet_grid(ping_rate_period ~ ., scales = "free_y")

# avg. adjusted ping rate histogram for before and after ping rate increase
ping_rate_increase_date <- ymd(20210101) # set to Jan. 1, 2021 based on plots above
dcrb_vms_tix_analysis_TripInfo %>% 
  select(Rec_ID, trip_VMSrecords, trip_start, trip_end, trip_duration_hours,
         avg_trip_ping_rate, VMSrecords_adjusted_trip) %>%
  distinct() %>%
  mutate(ping_rate_period = if_else(
    trip_start >= ping_rate_increase_date, 
      "post ping rate increase", 
      "pre ping rate increase"
    ),
    adjusted_ping_rate = VMSrecords_adjusted_trip * trip_VMSrecords / trip_duration_hours
  ) %>%
  ggplot(aes(x = adjusted_ping_rate, fill = ping_rate_period)) + 
  geom_histogram() + 
  facet_grid(ping_rate_period ~ ., scales = "free_y")
# the most boring histogram, every value is 1
```

```{r check vessel, revenue, and landings representation by VMS data}
# clear most of environment of everything except filtered VMS records and filters to apply to tickets data
keep_variables <- c(dcrb_vms_tix_analysis,
                    state_agency_code, target_rev, target_lbs, crab_years_to_vis)

rm(list = setdiff(ls(), keep_variables))

# load all fish tickets
fish_ticket_df <- read_rds(here('Confidential', 'processed', 'fish tickets', '2014fishtix_vlengths_withFTID.rds')) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2015fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2016fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2017fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2018fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2019fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2020fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2021fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2022fishtix_vlengths_withFTID.rds'))) %>%
  bind_rows(read_rds(here('Confidential', 'processed', 'fish tickets', '2023fishtix_vlengths_withFTID.rds')))

# apply same filters as dcrb_vms_tix_analysis, except for depth and speed which are from VMS
dcrb_ticket_df <- fish_ticket_df %>%
  filter(agency_code == state_agency_code) %>%
  filter(TARGET_rev == target_rev | TARGET_lbs == target_lbs) %>%
  mutate(
    year_month = paste0(lubridate::year(date),"_", substr(lubridate::ymd(date),6,7)),
    month_as_numeric = month(date),
    month_as_date = round_date(date, unit='month'),
    season = as.character(ifelse(month %in% winter_months, "Winter", "Spring-Summer")),
    crab_year = ifelse(
      month_as_numeric >= 11, paste0(year, "_", 1+year), paste0(year-1, "_", year)
    )
  ) %>%
  filter(crab_year %in% crab_years_to_vis) %>%
  dplyr::select(
      Rec_ID, # fish ticket ID
      drvid, # vessel ID
      FINAL_LENGTH,
      date,
      year,
      crab_year,
      year_month,
      month,
      month_as_numeric,
      month_as_date,
      season,
      pacfin_port_code,
      port_group_code,
      TARGET_lbs, # target species by weight (filtered to "DCRB")
      TARGET_rev, # target species by revenue (filtered to "DCRB") # TODO - check do I need to adjust revenue?
      DCRB_lbs, # dungeness crab catch weight
      DCRB_revenue # dungeness crab catch revenue
    )

# TODO need to update for inflation?
# code snippet from 04_match_vms_fishtix.Rmd, commented out there as well?
# adjust for inflation based on reference year using Fred deflators (added 8May2024)
# left_join(gdp_defl, by = YEAR) %>% #left_join(gdp_defl, by = c("year in fishtix_vms name" = "YEAR")
#   mutate(AFI_REVENUE = EXVESSEL_REVENUE / DEFL)

# select distinct ticket IDs from filtered VMS dataframe
dcrb_vms_rec_ids <- dcrb_vms_tix_analysis %>%
  select(Rec_ID) %>%
  distinct()

# add column to ticket dataframe for whether that ticket was represented in filtered VMS dataframe
dcrb_vms_representation_df <- left_join(dcrb_ticket_df, dcrb_vms_rec_ids, by = "Rec_ID", keep = TRUE) %>%
  mutate(represented_in_vms = !is.na(Rec_ID.y)) %>% # if ticket ID is NA in dcrb_vms_rec_ids, then the landings are not represented by VMS data
  select(-Rec_ID.y) %>%
  rename(Rec_ID = Rec_ID.x)

# count total 
dcrb_vms_representation_df %>% 
  group_by(month_as_date, represented_in_vms) %>%
  summarise(unique_vessels = n_distinct(drvid),
            total_landings = sum(DCRB_lbs),
            total_revenue = sum(DCRB_revenue)) %>% # TODO need to update for inflation?
  ggplot(aes(x = month_as_date, y = unique_vessels, color = represented_in_vms, fill = represented_in_vms)) +
  geom_col() + facet_grid(represented_in_vms ~ .)
# TODO reshape and facet by variable
# TODO calculate %'s
```


